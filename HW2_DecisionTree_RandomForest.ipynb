{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8b7888",
   "metadata": {},
   "source": [
    "## Homework 2: Decision Tree and Random Forest Implementation on Abalone Dataset\n",
    "\n",
    "**Objective:**  \n",
    "In this assignment, we implement a decision tree classifier and a random decision forest entirely from scratch, without using external libraries such as `scikit-learn` for model training.  \n",
    "We apply our models on the Abalone dataset, which contains physical measurements of abalone and aims to predict the number of rings (an approximation of age).  \n",
    "The dataset includes both categorical (Sex) and numeric features, making it a suitable candidate for tree-based models.\n",
    "\n",
    "---\n",
    "\n",
    "**Improving Accuracy with Label Grouping:**  \n",
    "In addition to using the original number of rings (ranging from 1 to 29) as classification labels, we introduce a grouped classification scheme to reduce class imbalance and increase model robustness:\n",
    "- Class 0 (Young): Rings 1–8  \n",
    "- Class 1 (Middle-aged): Rings 9–10  \n",
    "- Class 2 (Old): Rings 11 and above\n",
    "\n",
    "This grouping simplifies the classification task and enables the models to achieve more stable and interpretable results.\n",
    "\n",
    "---\n",
    "\n",
    "**Why Accuracy is Relatively Low with Original Labels:**  \n",
    "- The Abalone dataset is highly overlapping, where different input combinations may yield similar target values.\n",
    "- Although this is originally a regression problem, it is treated here as a multi-class classification task, increasing complexity.\n",
    "- Some ring classes are extremely rare, making the data highly imbalanced and prone to overfitting or underfitting.\n",
    "- Shallow decision trees underfit the data, while unpruned deep trees overfit.\n",
    "- Random forests reduce variance, but due to noise and label complexity, the overall accuracy may still remain modest.\n",
    "\n",
    "---\n",
    "\n",
    "**Performance Evaluation:**  \n",
    "We evaluate the models using 5-fold cross validation. For each fold:\n",
    "- Accuracy is computed\n",
    "- Confusion matrices are printed\n",
    "\n",
    "This evaluation is done for both:\n",
    "- Original multi-class labels (1–29 rings)\n",
    "- Grouped labels (3-category age bins)\n",
    "\n",
    "---\n",
    "\n",
    "**Structure of This Notebook:**\n",
    "1. Data loading and preprocessing (original and grouped labels)\n",
    "2. Implementation of decision tree construction\n",
    "3. Prediction function for decision trees\n",
    "4. Evaluation with k-fold cross validation and confusion matrices\n",
    "5. Pruned decision tree and evaluation\n",
    "6. Random forest implementation\n",
    "7. Random forest evaluation\n",
    "\n",
    "This notebook helps build a deep understanding of how decision trees and ensemble methods operate on real-world mixed-type data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be0ced",
   "metadata": {},
   "source": [
    "### 1. Implementation of Decision Tree Modeling Function\n",
    "\n",
    "This cell begins by loading the Abalone dataset, encoding the categorical feature (`Sex`) as integers, and separating the data into:\n",
    "- `X`: the feature matrix\n",
    "- `y`: the target vector (original ring counts)\n",
    "- `y_grouped`: an alternative target vector where ring counts are grouped into 3 age-based classes\n",
    "\n",
    "We also define the `attribute_types` list to indicate the type of each feature (categorical or numeric).\n",
    "\n",
    "Following preprocessing, we implement the core logic of the decision tree construction:\n",
    "- `entropy(y)`: computes class impurity for a given label distribution\n",
    "- `split_data(...)`: splits the dataset based on attribute type and threshold\n",
    "- `build_dt(...)`: recursively builds a decision tree by selecting the best attribute and threshold based on information gain\n",
    "- `Node` class: represents each node in the tree and stores the attribute index, split value, child nodes, and predicted label at leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a785cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
      "0    2   0.455     0.365   0.095        0.5140          0.2245   \n",
      "1    2   0.350     0.265   0.090        0.2255          0.0995   \n",
      "2    0   0.530     0.420   0.135        0.6770          0.2565   \n",
      "3    2   0.440     0.365   0.125        0.5160          0.2155   \n",
      "4    1   0.330     0.255   0.080        0.2050          0.0895   \n",
      "\n",
      "   Viscera weight  Shell weight  Rings  \n",
      "0          0.1010         0.150     15  \n",
      "1          0.0485         0.070      7  \n",
      "2          0.1415         0.210      9  \n",
      "3          0.1140         0.155     10  \n",
      "4          0.0395         0.055      7  \n",
      "Data Size (4177, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Column name\n",
    "columns = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight',\n",
    "           'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"abalone.data\", names=columns)\n",
    "\n",
    "# Encode categorical (sex)\n",
    "data['Sex'] = data['Sex'].astype('category').cat.codes\n",
    "\n",
    "X = data.drop('Rings', axis=1).values\n",
    "y = data['Rings'].values\n",
    "\n",
    "# Alternative path\n",
    "def convert_labels_to_classes(y):\n",
    "    y_new = np.zeros_like(y)\n",
    "    y_new[(y >= 1) & (y <= 8)] = 0  # Young\n",
    "    y_new[(y >= 9) & (y <= 10)] = 1  # Middle\n",
    "    y_new[y >= 11] = 2  # Old\n",
    "    return y_new\n",
    "\n",
    "y_grouped = convert_labels_to_classes(y)\n",
    "\n",
    "\n",
    "# Attribute types: 2 = categorical, 1 = numeric\n",
    "attribute_types = [2] + [1] * 7\n",
    "\n",
    "# Print first 5 row  \n",
    "print(data.head())\n",
    "print(\"Data Size\", X.shape)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probs = counts[np.nonzero(counts)] / len(y)\n",
    "    return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "def split_data(X, y, attr, value, is_categorical):\n",
    "    if is_categorical:\n",
    "        idx = X[:, attr] == value\n",
    "    else:\n",
    "        idx = X[:, attr] <= value\n",
    "    return X[idx], y[idx], X[~idx], y[~idx]\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attr=None, value=None, left=None, right=None, *, label=None):\n",
    "        self.attr = attr\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.label = label\n",
    "\n",
    "def build_dt(X, y, attribute_types, options=None):\n",
    "    if len(set(y)) == 1:\n",
    "        return Node(label=y[0])\n",
    "    if X.shape[1] == 0 or len(y) == 0:\n",
    "        return Node(label=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    best_gain = -1\n",
    "    best_attr, best_val = None, None\n",
    "    best_splits = None\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        values = np.unique(X[:, i])\n",
    "        for val in values:\n",
    "            Xl, yl, Xr, yr = split_data(X, y, i, val, attribute_types[i] == 2)\n",
    "            if len(yl) == 0 or len(yr) == 0:\n",
    "                continue\n",
    "            gain = entropy(y) - (len(yl)/len(y))*entropy(yl) - (len(yr)/len(y))*entropy(yr)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attr = i\n",
    "                best_val = val\n",
    "                best_splits = (Xl, yl, Xr, yr)\n",
    "\n",
    "    if best_gain == -1:\n",
    "        return Node(label=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    left = build_dt(best_splits[0], best_splits[1], attribute_types, options)\n",
    "    right = build_dt(best_splits[2], best_splits[3], attribute_types, options)\n",
    "    return Node(attr=best_attr, value=best_val, left=left, right=right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d31a5e",
   "metadata": {},
   "source": [
    "### 2. Implementation of Decision Tree Testing Function\n",
    "\n",
    "This cell implements the `predict_dt` function, which applies a trained decision tree to a set of test samples.\n",
    "\n",
    "The function relies on a recursive helper method `traverse(node, x)` to classify a single sample by walking down the tree:\n",
    "- At each decision node, it checks whether the splitting attribute is categorical or numeric.\n",
    "- Based on the attribute type and the sample's feature value, it chooses the appropriate child (left or right).\n",
    "- Once a terminal (leaf) node is reached, the corresponding class label is returned.\n",
    "\n",
    "The outer function applies this traversal to each row in the input matrix `X` and returns a vector of predicted class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff26a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dt(dt, X, options=None):\n",
    "    def traverse(node, x):\n",
    "        if node.label is not None:\n",
    "            return node.label\n",
    "        val = x[node.attr]\n",
    "        if attribute_types[node.attr] == 2:\n",
    "            branch = node.left if val == node.value else node.right\n",
    "        else:\n",
    "            branch = node.left if val <= node.value else node.right\n",
    "        return traverse(branch, x)\n",
    "    return np.array([traverse(dt, x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7436a",
   "metadata": {},
   "source": [
    "### 3. Results of k-Fold Cross Validation\n",
    "\n",
    "In this cell, we evaluate the decision tree classifier using 5-fold cross validation on both the original labels and the grouped 3-class labels.\n",
    "\n",
    "The `evaluate_model_versions` function performs the following steps for each fold:\n",
    "- Splits the data into training and testing sets,\n",
    "- Trains a decision tree separately on both `y` (original ring counts) and `y_grouped` (age-based classes),\n",
    "- Predicts the labels on the test set for each version,\n",
    "- Calculates and stores the accuracy for each fold,\n",
    "- Computes and prints the mean accuracy across all folds.\n",
    "\n",
    "This dual evaluation setup allows us to compare the impact of class grouping on classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae60e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy Scores: [0.19856459330143542, 0.22488038277511962, 0.19640718562874251, 0.19401197604790418, 0.17485029940119762]\n",
      "Mean Accuracy (Original): 0.1977428874308799\n",
      "\n",
      "Grouped Accuracy Scores: [0.5885167464114832, 0.5741626794258373, 0.5652694610778443, 0.5796407185628742, 0.5532934131736527]\n",
      "Mean Accuracy (Grouped): 0.5721766037303384\n",
      "\n",
      "Fold 1 - Original Confusion Matrix:\n",
      "[[ 1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  2  3  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  6 11  8  5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  8 10 13 10  2  1  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  5 17 16 21  8  6  4  2  1  1  1  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  4 11 26 30 13  8  2  1  1  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  6 32 29 26 23  6  8  5  3  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  6 12 30 33 23  9  8  4  2  2  4  0  2  1  1  0  0  0  0]\n",
      " [ 0  0  0  1  4 11 12 20 20  7  6  2  2  2  1  1  0  2  1  0  1  0  0]\n",
      " [ 0  0  0  0  1  5  6  9  8  5  2  4  1  5  1  1  0  1  0  0  1  0  1]\n",
      " [ 0  0  0  0  0  1  3  5  4  5  6  3  1  0  1  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  3  3  4  3  1  2  3  2  1  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  3  3  3  2  3  3  1  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  1  2  2  1  1  1  1  0  1  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  2  2  0  0  0  0  0  1  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  3  2  3  0  0  0  0  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  2  0  2  0  0  0  0  0  0  1  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  1  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 1 - Grouped Confusion Matrix:\n",
      "[[201  52  26]\n",
      " [ 52 128 101]\n",
      " [ 30  83 163]]\n",
      "\n",
      "Fold 2 - Original Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  4  1  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  9  7  7  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  2 16 15  8  4  3  0  1  0  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  6 15 24 23 13  5  2  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6 15 33 18 23 11  3  2  1  1  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  1  4 15 20 33 28 13 11  5  2  3  0  1  1  1  1  0  0  0  0]\n",
      " [ 0  0  0  2  5  7 19 31 30  8  3  4  0  1  4  3  1  0  0  0  0  0]\n",
      " [ 0  0  0  2  1  4 16 20 21 12  6  3  5  0  3  1  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  6  9 13  4 10  4  3  1  1  2  0  3  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  2  7  9  7  0  5  6  1  1  2  0  0  1  0  1  1  0]\n",
      " [ 0  0  0  0  0  0  3  4  2  2  1  1  5  0  0  1  0  0  0  2  0  1]\n",
      " [ 0  0  0  1  0  3  2  3  5  0  1  4  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  2  2  1  1  1  0  0  1  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  3  0  0  2  1  2  0  0  0  1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  1  0  0  1  0  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 2 - Grouped Confusion Matrix:\n",
      "[[217  51  32]\n",
      " [ 64 101  92]\n",
      " [ 27  90 162]]\n",
      "\n",
      "Fold 3 - Original Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  1  4  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  1  4  5  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  2  2 10  0  4  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  4 17 19 11  1  2  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  4 11 22 13 14  7  3  0  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  0  8 16 25 23 13  8  8  0  1  3  0  2  0  1  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  0  2  8 21 32 23 21  8  5  4  3  2  0  0  0  0  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  2  9 18 29 23 14 10  5  6  3  0  4  3  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  1  8 27 16 18 14  1  0  1  0  1  2  0  3  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  1  2  7 10 10  9  2  1  3  4  0  1  1  0  0  0  0  0  1\n",
      "   0]\n",
      " [ 0  0  0  0  0  2  3  4  7  3  5  5  4  1  3  3  1  2  0  0  0  0  0  1\n",
      "   0]\n",
      " [ 0  0  0  0  0  1  0  2  3  4  3  3  0  1  5  1  1  0  1  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  4  2  3  0  1  1  1  1  1  1  1  4  0  0  0  0  1\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  1  0  1  3  2  0  1  1  2  1  0  1  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  1  2  1  2  1  0  0  0  3  0  0  1  2  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  1  1  2  1  1  0  1  1  0  1  0  0  0  1  1  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  1  2  1  0  2  0  3  0  0  1  0  0  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  1  1  2  0  0  0  0  1  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0]]\n",
      "Fold 3 - Grouped Confusion Matrix:\n",
      "[[190  66  28]\n",
      " [ 64 109  84]\n",
      " [ 32  89 173]]\n",
      "\n",
      "Fold 4 - Original Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  3  5  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  3  8  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  9 13 14 11  0  1  2  0  2  0  1  0  0  0  0  1  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  2 10 20 19  9  1  1  2  0  1  0  1  1  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  4  7 23 25 29 17 15  3  3  3  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  6 15 22 29 25 16 11  5  0  2  2  2  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  2  3 10 21 27 24  3  3  3  1  1  1  1  2  2  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  1  6  4 15 16 16 14 12  4  3  4  1  0  1  0  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  4 10  9 10 12  5  2  1  1  2  3  0  0  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  1  4  3  9  1  4  3  0  2  0  4  1  0  2  0  0  1  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  1  1  4  1  6  4  4  4  1  1  1  1  2  0  1  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  2  3  5  2  1  0  1  1  0  1  2  2  1  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  1  1  0  1  1  2  2  2  0  1  2  0  1  0  2  1  1  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  1  5  1  0  3  0  0  1  0  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  1  1  3  0  1  0  2  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  1  1  1  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0  1  1  1  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  1  1  1  1  1  0  0  1  0  1  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0]]\n",
      "Fold 4 - Grouped Confusion Matrix:\n",
      "[[189  62  34]\n",
      " [ 54 107  78]\n",
      " [ 22 101 188]]\n",
      "\n",
      "Fold 5 - Original Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  4  0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  7  6  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  7 10 13 11  2  1  0  1  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2 11 20 29  3  4  0  0  1  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  5 20 22 35 14  8  2  3  1  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  1  3 11 23 29 34 20  4  6  5  1  1  2  1  1  0  0  0  0  0]\n",
      " [ 0  0  1  1  3 20 33 25 23 17  6  4  5  1  5  1  1  0  0  0  1  0]\n",
      " [ 0  0  0  2  2  9 12 30 20 14  4  4  1  4  3  2  0  0  0  0  1  0]\n",
      " [ 0  0  0  1  0  4  6 10 11  1  6  3  0  1  0  2  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  5 10  6 10  4  5  3  1  0  2  1  0  2  0  0  0  0]\n",
      " [ 0  0  0  1  0  4  4  1  2  1  0  2  2  0  1  0  1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  3  6  1  0  2  0  2  1  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  2  3  1  1  2  1  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  1  2  0  3  2  0  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  2  0  0  1  1  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  1  0  2  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 5 - Grouped Confusion Matrix:\n",
      "[[185  50  24]\n",
      " [ 55 119 115]\n",
      " [ 28 101 158]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def evaluate_model_versions(X, y_original, y_grouped, attribute_types, builder, predictor, options=None, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accs_orig, accs_grouped = [], []\n",
    "    confs_orig, confs_grouped = [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "        # Orjinal\n",
    "        dt_orig = builder(X[train_idx], y_original[train_idx], attribute_types, options)\n",
    "        y_pred_orig = predictor(dt_orig, X[test_idx], options)\n",
    "        accs_orig.append(accuracy_score(y_original[test_idx], y_pred_orig))\n",
    "        confs_orig.append(confusion_matrix(y_original[test_idx], y_pred_orig))\n",
    "\n",
    "        # Group\n",
    "        dt_grp = builder(X[train_idx], y_grouped[train_idx], attribute_types, options)\n",
    "        y_pred_grp = predictor(dt_grp, X[test_idx], options)\n",
    "        accs_grouped.append(accuracy_score(y_grouped[test_idx], y_pred_grp))\n",
    "        confs_grouped.append(confusion_matrix(y_grouped[test_idx], y_pred_grp))\n",
    "\n",
    "   \n",
    "    print(\"Original Accuracy Scores:\", accs_orig)\n",
    "    print(\"Mean Accuracy (Original):\", np.mean(accs_orig))\n",
    "    print(\"\\nGrouped Accuracy Scores:\", accs_grouped)\n",
    "    print(\"Mean Accuracy (Grouped):\", np.mean(accs_grouped))\n",
    "\n",
    " \n",
    "    for i, (conf_o, conf_g) in enumerate(zip(confs_orig, confs_grouped), 1):\n",
    "        print(f\"\\nFold {i} - Original Confusion Matrix:\\n{conf_o}\")\n",
    "        print(f\"Fold {i} - Grouped Confusion Matrix:\\n{conf_g}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model_versions(X, y, y_grouped, attribute_types, build_dt, predict_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726abd17",
   "metadata": {},
   "source": [
    "### 4. Implementation of Decision Tree Function with Depth-Based Pruning\n",
    "\n",
    "This cell introduces a depth-limited variant of the decision tree builder via the `build_dt_pruned` function.\n",
    "\n",
    "Key enhancements:\n",
    "- A `max_depth` parameter is added to restrict the depth of the tree.\n",
    "- During recursion, if the current depth reaches or exceeds `max_depth`, the algorithm stops further splitting and returns a leaf node with the majority class label in the current subset.\n",
    "- This approach helps prevent overfitting by controlling model complexity.\n",
    "\n",
    "All other aspects of the decision tree construction—such as entropy calculation, data splitting, and selection of the best split based on information gain—remain unchanged from the original `build_dt` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dt_pruned(X, y, attribute_types, max_depth, depth=0):\n",
    "    if len(set(y)) == 1 or depth >= max_depth:\n",
    "        return Node(label=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    best_gain = -1\n",
    "    best_attr, best_val = None, None\n",
    "    best_splits = None\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        values = np.unique(X[:, i])\n",
    "        for val in values:\n",
    "            Xl, yl, Xr, yr = split_data(X, y, i, val, attribute_types[i] == 2)\n",
    "            if len(yl) == 0 or len(yr) == 0:\n",
    "                continue\n",
    "            gain = entropy(y) - (len(yl)/len(y))*entropy(yl) - (len(yr)/len(y))*entropy(yr)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attr = i\n",
    "                best_val = val\n",
    "                best_splits = (Xl, yl, Xr, yr)\n",
    "\n",
    "    if best_gain == -1:\n",
    "        return Node(label=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    left = build_dt_pruned(best_splits[0], best_splits[1], attribute_types, max_depth, depth + 1)\n",
    "    right = build_dt_pruned(best_splits[2], best_splits[3], attribute_types, max_depth, depth + 1)\n",
    "    return Node(attr=best_attr, value=best_val, left=left, right=right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056f886",
   "metadata": {},
   "source": [
    "### 5. Results of k-Fold Cross Validation (with Pruning)\n",
    "\n",
    "In this cell, we evaluate the performance of the depth-pruned decision tree using 5-fold cross validation on both the original and grouped label sets.\n",
    "\n",
    "The `evaluate_model_versions` function is used in combination with a lambda wrapper around `build_dt_pruned`, where the maximum tree depth is explicitly limited (e.g., `max_depth=5`).\n",
    "\n",
    "This setup allows us to observe how depth-based pruning influences model generalization by:\n",
    "- Reducing tree complexity,\n",
    "- Controlling overfitting on the training data.\n",
    "\n",
    "The printed results include fold-wise accuracy values and their mean for both labeling strategies, enabling a direct comparison with the unpruned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de24d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy Scores: [0.28827751196172247, 0.27751196172248804, 0.2622754491017964, 0.22994011976047904, 0.2682634730538922]\n",
      "Mean Accuracy (Original): 0.2652537031200756\n",
      "\n",
      "Grouped Accuracy Scores: [0.6100478468899522, 0.6255980861244019, 0.6287425149700598, 0.6239520958083832, 0.6095808383233533]\n",
      "Mean Accuracy (Grouped): 0.61958427642323\n",
      "\n",
      "Fold 1 - Original Confusion Matrix:\n",
      "[[ 2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  9  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 12 10  7  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  7 19 13  5  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  2 18 23 24 12  4  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  1 10 48 25 11  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  7 33 46 48  6  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2 29 29 61 10  0  1  0  0  7  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  6 21 39 19  0  0  0  0  6  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  4  7 22 10  0  1  1  0  4  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  4 14  7  0  0  1  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  4 15  2  0  3  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 15  1  0  3  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  6  2  0  0  0  0  4  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  2  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  9  0  0  0  1  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  2  0  1  1  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  0  1  0  1  0  0  0  0  0  0  0]]\n",
      "Fold 1 - Grouped Confusion Matrix:\n",
      "[[186  56  37]\n",
      " [ 36 129 116]\n",
      " [ 15  66 195]]\n",
      "\n",
      "Fold 2 - Original Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  3  0  3  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 12  3 10  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  6  5 28  5  6  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  3 15 33 23 12  6  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  2 11 39 34 22  1  0  5  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 10 22 46 47  4  0  9  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  5 29 60 12  0 11  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  4 17 44 25  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  4  8 27  9  0 10  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  3 21  8  0  8  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  9  6  0  4  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  1  4 11  4  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  2  4  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  6  3  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  2  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 2 - Grouped Confusion Matrix:\n",
      "[[242  44  14]\n",
      " [ 69 125  63]\n",
      " [ 26  97 156]]\n",
      "\n",
      "Fold 3 - Original Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  2  7  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  5  4  9  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  4  9 34  4  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  3 33 21 16  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3 17 41 33 10  2  2  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  4 21 57 37  6  3  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  3  8 46 38 15  9  3  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  6 24 37 15  3  3  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  4 12 11 10 11  2  1  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3  8 12  6  7  3  4  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  8  6  3  3  1  2  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  5  3  1  3  6  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  5  2  4  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  2  2  3  2  2  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  3  1  1  1  1  0  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3  3  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  0  2  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 3 - Grouped Confusion Matrix:\n",
      "[[227  41  16]\n",
      " [ 52  96 109]\n",
      " [ 24  68 202]]\n",
      "\n",
      "Fold 4 - Original Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  8  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  7  9  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4 10 12 18  4  3  3  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2 10 22 18 11  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  7 17 47 40 13  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  3 41 51 27  6  0  5  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3 22 42 25  6  0  5  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  8 29 38 13  0  7  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  6 15 20 15  0  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3  8 12  3  0  4  2  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3  5 11  5  0  6  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  3  7  2  0  6  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  9  1  0  6  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  6  2  0  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  3  2  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  1  0  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  2  1  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 4 - Grouped Confusion Matrix:\n",
      "[[209  59  17]\n",
      " [ 55 122  62]\n",
      " [ 22  99 190]]\n",
      "\n",
      "Fold 5 - Original Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2 11  4  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 12 10 16  3  3  1  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2 14 32 11  9  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  9 20 24 43 16  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  9 20 50 49 11  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  1 13 32 66 23  2  3  0  5  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  7 24 44 20  5  3  0  3  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  3  9 16  8  2  4  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  4  6 18 11  2  4  0  4  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3  7  1  0  4  0  4  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  3  6  2  0  3  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  2  7  1  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  6  1  0  3  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  4  1  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  2  1  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 5 - Grouped Confusion Matrix:\n",
      "[[185  60  14]\n",
      " [ 46 102 141]\n",
      " [ 24  41 222]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_versions(X, y,y_grouped, attribute_types, lambda x, y, t, o: build_dt_pruned(x, y, t, 5), predict_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560671bf",
   "metadata": {},
   "source": [
    "### 6. Implementation of Random Decision Forest (RDF)\n",
    "\n",
    "This cell implements a basic version of a Random Decision Forest (RDF) by constructing and combining multiple decision trees.\n",
    "\n",
    "- `build_rdf`: Generates an ensemble of `N` decision trees, where each tree is trained on a different bootstrap sample drawn with replacement from the training set.\n",
    "- `predict_rdf`: Applies all trees to the test set and performs majority voting across the individual predictions to determine the final class labels.\n",
    "\n",
    "This ensemble method improves model stability and prediction accuracy by reducing the variance associated with individual decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa41b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_rdf(X, y, attribute_types, N, options=None):\n",
    "    trees = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    for _ in range(N):\n",
    "        indices = rng.choice(len(X), len(X), replace=True)\n",
    "        X_sample, y_sample = X[indices], y[indices]\n",
    "        tree = build_dt(X_sample, y_sample, attribute_types, options)\n",
    "        trees.append(tree)\n",
    "    return trees\n",
    "\n",
    "\n",
    "def predict_rdf(rdf, X, options=None):\n",
    "    predictions = np.array([predict_dt(tree, X) for tree in rdf])\n",
    "    return np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ccdc1",
   "metadata": {},
   "source": [
    "### 7. Results of k-Fold Cross Validation (Random Decision Forest)\n",
    "\n",
    "In this cell, we evaluate the Random Decision Forest (RDF) using 5-fold cross validation on both the original and grouped class labels.\n",
    "\n",
    "The `evaluate_rdf_versions` function performs the following operations for each fold:\n",
    "- Constructs an ensemble of `N` decision trees using bootstrapped training samples,\n",
    "- Predicts the test set labels using majority voting across the ensemble,\n",
    "- Computes and stores the classification accuracy for both the original and grouped target formats.\n",
    "\n",
    "After all folds are processed, the function prints per-fold accuracy and the mean accuracy, followed by confusion matrices for each fold and label format.  \n",
    "This evaluation allows for a direct comparison of ensemble performance relative to single decision trees, as well as the impact of label grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc2a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF Original Accuracy Scores: [0.2284688995215311, 0.22727272727272727, 0.2155688622754491, 0.22275449101796407, 0.1844311377245509]\n",
      "Mean Accuracy (Original): 0.2156992235624445\n",
      "\n",
      "RDF Grouped Accuracy Scores: [0.6160287081339713, 0.5956937799043063, 0.6227544910179641, 0.6071856287425149, 0.6191616766467066]\n",
      "Mean Accuracy (Grouped): 0.6121648568890927\n",
      "\n",
      "Fold 1 - RDF Original Confusion Matrix:\n",
      "[[ 1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  8  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  6 11 10  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  5 12 15 11  2  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3 16 22 22 10  5  3  1  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  3 16 33 19 12  5  4  0  3  0  1  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  2 11 21 36 37 18  7  6  2  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  6 11 34 32 22  6 10  3  6  2  1  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  1  8 18 29 16  8  5  2  1  2  2  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  2  5 11 11  9  6  2  1  1  1  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  3  3  6  4  4  5  3  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  2  3  4  3  4  3  3  2  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  2  2  5  1  1  5  2  1  1  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  3  2  1  1  2  1  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  2  1  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  3  2  1  1  0  3  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  2  0  2  0  1  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  1  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  1  0  0  1  0  0  0  0  0  0  0]]\n",
      "Fold 1 - RDF Grouped Confusion Matrix:\n",
      "[[213  47  19]\n",
      " [ 51 126 104]\n",
      " [ 21  79 176]]\n",
      "\n",
      "Fold 2 - RDF Original Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  5  2  0  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  5 10  7  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5 13 14 13  2  4  0  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  4 20 24 31  3  4  5  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  7 16 35 23 14 12  0  3  2  0  1  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  4 13 29 39 23 17  3  5  1  3  1  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  9 27 34 27  5  8  3  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  1  2  7 18 22 23  8  4  2  3  1  2  1  1  0  1  0  0]\n",
      " [ 0  0  0  0  1  2 11 16 10  7  3  2  1  1  1  1  1  0  0  1  0]\n",
      " [ 0  0  0  1  0  4  5 11  4  4  6  2  2  1  0  1  2  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  7  4  3  3  0  2  2  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  1  2  7  5  1  0  1  1  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  1  1  1  2  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  4  0  0  1  1  0  0  1  0  1  1  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  1  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  2  1  2  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0]]\n",
      "Fold 2 - RDF Grouped Confusion Matrix:\n",
      "[[212  65  23]\n",
      " [ 47 125  85]\n",
      " [ 20  98 161]]\n",
      "\n",
      "Fold 3 - RDF Original Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  1  4  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  5  1  5  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  4  5  6  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  1  0  5 19 20  6  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  4 15 19 13 17  5  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  2  8 21 32 21 12  6  4  0  0  0  1  2  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  1  0  3 10 20 39 28 13  8  2  2  3  1  1  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  1  2  9 13 31 31 21 10  5  1  0  0  1  1  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  1  2  7 17 25 17 10  3  2  4  1  1  1  1  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  1  0  2 10  8 15  8  2  2  0  0  2  0  0  0  1  0  0  0  1\n",
      "   0]\n",
      " [ 0  0  0  0  0  2  3  7  8  5  4  4  4  1  3  2  0  0  1  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  1  2  6  2  2  2  2  3  3  1  0  1  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  1  2  3  7  1  1  1  0  1  1  1  1  1  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  2  0  2  1  4  1  2  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  4  1  2  1  1  2  0  0  0  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  1  0  2  1  1  3  1  0  0  1  0  0  0  0  0  1  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  1  2  2  2  0  0  3  1  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  2  0  0  1  0  0  0  1  1  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]]\n",
      "Fold 3 - RDF Grouped Confusion Matrix:\n",
      "[[213  57  14]\n",
      " [ 56 111  90]\n",
      " [ 18  80 196]]\n",
      "\n",
      "Fold 4 - RDF Original Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  2  5  3  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  2  5  7  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  2  5 15 22  6  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  1 10 23 13 12  6  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  1  8 22 30 34 20  4  4  4  2  0  0  0  1  1  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  2  2  9 30 37 24 17  5  5  1  1  0  0  1  1  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  1  2 10 29 31 17  4  4  2  2  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  1]\n",
      " [ 0  0  0  0  2  3  8 16 21 23  6  6  2  5  3  0  0  0  3  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  1  4 16  9 15  8  2  1  3  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  1  0  1  6  7  7  3  3  0  0  1  1  1  0  0  1  1  2  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  1  1  4  6  8  4  4  2  1  2  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  1  0  2  5  5  0  2  3  0  1  0  0  0  2  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  3  1  4  1  0  1  2  1  1  1  1  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  2  2  1  1  3  1  0  0  1  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  2  0  2  1  1  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  2  0  1  0  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  1  0  1  0  0  2  1  0  0  0  0  0  0  0  0\n",
      "   1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]]\n",
      "Fold 4 - RDF Grouped Confusion Matrix:\n",
      "[[196  65  24]\n",
      " [ 61 108  70]\n",
      " [ 20  88 203]]\n",
      "\n",
      "Fold 5 - RDF Original Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  3  3  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  2  4 10  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  8 10 10 12  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 18 18 20  9  1  3  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  3 10 20 18 31 17 10  1  2  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  8 27 43 30 17  5  4  3  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  5 17 33 30 27 14  7  3  4  3  2  0  0  0  0  0  1]\n",
      " [ 0  0  0  2  2  7 20 28 18 15  5  3  1  2  3  1  0  1  0  0  0]\n",
      " [ 0  0  0  1  2  1  8  8 13  3  3  4  0  0  1  1  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  5  7  6 11  7  5  1  1  3  1  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  3  3  2  2  1  3  1  3  0  1  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  3  2  6  1  2  2  0  1  1  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  1  1  1  2  2  0  1  2  1  0  0  1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  3  3  0  2  0  0  2  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0  2  1  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  2  0  0  1  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  1  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Fold 5 - RDF Grouped Confusion Matrix:\n",
      "[[187  49  23]\n",
      " [ 57 145  87]\n",
      " [ 22  80 185]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rdf_versions(X, y_original, y_grouped, attribute_types, N, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accs_orig, accs_grouped = [], []\n",
    "    confs_orig, confs_grouped = [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "        # RDF Orjinal\n",
    "        rdf_orig = build_rdf(X[train_idx], y_original[train_idx], attribute_types, N)\n",
    "        y_pred_orig = predict_rdf(rdf_orig, X[test_idx])\n",
    "        accs_orig.append(accuracy_score(y_original[test_idx], y_pred_orig))\n",
    "        confs_orig.append(confusion_matrix(y_original[test_idx], y_pred_orig))\n",
    "\n",
    "        # RDF Group\n",
    "        rdf_grp = build_rdf(X[train_idx], y_grouped[train_idx], attribute_types, N)\n",
    "        y_pred_grp = predict_rdf(rdf_grp, X[test_idx])\n",
    "        accs_grouped.append(accuracy_score(y_grouped[test_idx], y_pred_grp))\n",
    "        confs_grouped.append(confusion_matrix(y_grouped[test_idx], y_pred_grp))\n",
    "\n",
    "    \n",
    "    print(\"RDF Original Accuracy Scores:\", accs_orig)\n",
    "    print(\"Mean Accuracy (Original):\", np.mean(accs_orig))\n",
    "    print(\"\\nRDF Grouped Accuracy Scores:\", accs_grouped)\n",
    "    print(\"Mean Accuracy (Grouped):\", np.mean(accs_grouped))\n",
    "\n",
    "   \n",
    "    for i, (conf_o, conf_g) in enumerate(zip(confs_orig, confs_grouped), 1):\n",
    "        print(f\"\\nFold {i} - RDF Original Confusion Matrix:\\n{conf_o}\")\n",
    "        print(f\"Fold {i} - RDF Grouped Confusion Matrix:\\n{conf_g}\")\n",
    "\n",
    "evaluate_rdf_versions(X, y, y_grouped, attribute_types, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
